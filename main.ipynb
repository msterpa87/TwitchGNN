{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "\n",
    "from models import *\n",
    "from utils import *\n",
    "\n",
    "import warnings\n",
    "from scipy.sparse import SparseEfficiencyWarning\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=SparseEfficiencyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEval():\n",
    "    def __init__(self, print_freq=10, continual_learning=False, ewc_type='add',\n",
    "                 lambda_=0.1, verbose=True, print_previous_val=False, use_dropout=False):\n",
    "        super(ModelEval, self).__init__()\n",
    "\n",
    "        self.print_freq = print_freq\n",
    "        self.tasks = load_tasks()\n",
    "        self.prior_weights = dict()\n",
    "        self.fisher_matrix = dict()\n",
    "        self.loss_fn = CategoricalCrossentropy()\n",
    "        self.mean_accuracy = GlobalAccuracy()\n",
    "        self.backward_transfer = BackwardTransfer(len(self.tasks))\n",
    "        self.continual_learning = continual_learning\n",
    "        self.lambda_ = lambda_\n",
    "        self.model = None\n",
    "        self.verbose = verbose\n",
    "        self.print_previous_val = print_previous_val\n",
    "        self.optim = None\n",
    "        self.use_dropout = use_dropout\n",
    "\n",
    "        assert(ewc_type in ['add', 'combine', 'last'])\n",
    "        self.ewc_type = ewc_type\n",
    "    \n",
    "    def train(self, task_num, epochs=50, lr=0.001):\n",
    "        (x, adj, y), (mask_tr, _, _) = self.tasks[task_num]\n",
    "\n",
    "        # initialize model if not already trained\n",
    "        if self.model is None:\n",
    "            self.model = GNNNodeClassifier(use_dropout=self.use_dropout)\n",
    "            self.optim = Adam(learning_rate=lr)\n",
    "        \n",
    "        accuracy = CategoricalAccuracy()\n",
    "\n",
    "        train_acc_list = []\n",
    "        train_loss_list = []\n",
    "        val_acc_list = {i: [] for i in range(task_num+1)}\n",
    "        val_loss_list = {i: [] for i in range(task_num+1)}\n",
    "        \n",
    "        for i in range(epochs+1):\n",
    "            with tf.GradientTape() as tape:\n",
    "                pred = self.model([x, adj])\n",
    "                train_loss = self.loss_fn(y[mask_tr], pred[mask_tr])\n",
    "\n",
    "                # add EWC penalty if training with continual learning\n",
    "                if self.continual_learning:\n",
    "                    train_loss += self.ewc_penalty(task_num)\n",
    "                \n",
    "            accuracy.update_state(y_pred=pred[mask_tr], y_true=y[mask_tr])\n",
    "\n",
    "            gradients = tape.gradient(train_loss, self.model.trainable_variables)\n",
    "            self.optim.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
    "\n",
    "            train_acc = accuracy.result().numpy()\n",
    "            \n",
    "            if i % self.print_freq == 0 and self.verbose:\n",
    "                val_loss, val_acc = self.test(task_num, validation=True, print_acc=False)\n",
    "                s = f\"epoch={i}, train_loss={train_loss:.3f}, train_acc={train_acc:.3f}, val_acc={val_acc:.3f}\"\n",
    "\n",
    "                # saving data for plotting\n",
    "                train_acc_list.append(train_acc)\n",
    "                train_loss_list.append(train_loss.numpy())\n",
    "                val_acc_list[task_num].append(val_acc)\n",
    "                val_loss_list[task_num].append(val_loss.numpy())\n",
    "\n",
    "                # appending summary on previous training set\n",
    "                if self.print_previous_val:\n",
    "                    for j in range(task_num):\n",
    "                        prev_loss, prev_acc = self.test(j, validation=True, print_acc=False)\n",
    "                        s += f\", task[{j}]_val_acc={prev_acc:.3f}\"\n",
    "                        val_acc_list[j].append(prev_acc)\n",
    "                        val_loss_list[j].append(prev_loss.numpy())\n",
    "\n",
    "                print(s)\n",
    "        \n",
    "        # after training on current task add accuracy on previous tasks\n",
    "        for i in range(task_num+1):\n",
    "            (x_i, a_i, y_i), (_, _, mask_te_i) = self.tasks[i]\n",
    "            y_pred_i = self.model([x_i, a_i])[mask_te_i]\n",
    "            y_true_i = y_i[mask_te_i]\n",
    "\n",
    "            self.mean_accuracy.update_state(y_pred=y_pred_i, y_true=y_true_i)\n",
    "            \n",
    "            self.backward_transfer.update_state(task_i=i, task_j=task_num,\n",
    "                                                y_pred=y_pred_i, y_true=y_true_i)\n",
    "\n",
    "        # save the flatted list of parameters and fisher matrix of current model\n",
    "        self.prior_weights[task_num] = flat_tensor_list(self.model.trainable_variables)\n",
    "        self.fisher_matrix[task_num] = self.compute_fisher(task_num)\n",
    "\n",
    "        return train_loss_list, train_acc_list, val_loss_list, val_acc_list\n",
    "    \n",
    "    def compute_fisher(self, task_num):\n",
    "        \"\"\" Computes the diagonal Fisher matrix of the model parameters on the target task \"\"\"\n",
    "        with tf.GradientTape() as tape:\n",
    "            (x, a, y), (mask_tr, _, _) = self.tasks[task_num]\n",
    "            pred = self.model([x, a])\n",
    "            loss = self.loss_fn(y_pred=pred[mask_tr], y_true=y[mask_tr])\n",
    "        \n",
    "        gradients = tape.gradient(loss, self.model.trainable_variables)\n",
    "\n",
    "        return flat_tensor_list(gradients)**2\n",
    "    \n",
    "    def ewc_penalty(self, task_num):\n",
    "        \"\"\" Computes the EWC penalty for the target task \"\"\"\n",
    "        penalty = 0\n",
    "\n",
    "        # current parameters\n",
    "        theta_new = flat_tensor_list(self.model.trainable_variables)\n",
    "        matrices = list(self.fisher_matrix.values())\n",
    "\n",
    "        # the penalty is computed depending on the type of aggregation chosen\n",
    "        if self.ewc_type == 'add':\n",
    "            # compute an individual penalty loss for each previous task\n",
    "            for j in range(task_num):\n",
    "                fisher_mat = self.fisher_matrix[j]\n",
    "                theta = self.prior_weights[j]\n",
    "                penalty += self.lambda_ * tf.reduce_sum(fisher_mat * ((theta-theta_new)**2))\n",
    "        elif self.ewc_type == 'combine':\n",
    "            # sum an individual penalty loss using the same aggregate fisher matrix (sum)\n",
    "            if len(matrices):\n",
    "                fisher_sum = tf.reduce_sum(list(model_eval.fisher_matrix.values()), axis=0)\n",
    "\n",
    "                for j in range(task_num):\n",
    "                    theta = self.prior_weights[j]\n",
    "                    penalty += self.lambda_ * tf.reduce_sum(fisher_sum * ((theta-theta_new)**2))\n",
    "        elif self.ewc_type == 'last':\n",
    "            # use only the last fisher matrix\n",
    "            if len(matrices):\n",
    "                theta = self.prior_weights[-1]\n",
    "                penalty += self.lambda_ * tf.reduce_sum(matrices[-1] * ((theta-theta_new)**2))\n",
    "\n",
    "        return penalty\n",
    "\n",
    "    def test(self, task_num, validation=False, print_acc=True):\n",
    "        \"\"\" Test the model on task_num and return the accuracy\n",
    "\n",
    "        Args:\n",
    "            task_num (int): target task\n",
    "            validation (bool, optional): if True performs the test on the validation set. Defaults to False.\n",
    "            print_acc (bool, optional): if True prints the accuracy on console. Defaults to True.\n",
    "\n",
    "        Returns:\n",
    "            float: test accuracy\n",
    "        \"\"\"\n",
    "        (x, adj, y), (_, mask_va, mask_te) = self.tasks[task_num]\n",
    "\n",
    "        mask = [mask_te, mask_va][validation]\n",
    "\n",
    "        pred = self.model([x, adj])\n",
    "        loss = self.loss_fn(y[mask], pred[mask])\n",
    "\n",
    "        accuracy = CategoricalAccuracy()\n",
    "        accuracy.update_state(y_pred=pred[mask], y_true=y[mask])\n",
    "        acc = accuracy.result().numpy()\n",
    "        \n",
    "        if print_acc:\n",
    "            print(f\"accuracy task {task_num} = {acc:.3f}\")\n",
    "        \n",
    "        return loss, acc\n",
    "    \n",
    "    def print_mean_accuracy(self):\n",
    "        acc = self.mean_accuracy.result().numpy()\n",
    "        print(f\"mean_accuracy = {acc:.3f}\")\n",
    "    \n",
    "    def print_backward_transfer(self):\n",
    "        acc = self.backward_transfer.result().numpy()\n",
    "        print(f\"backward_transfer = {acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing node features\n",
      "Accuracy for target task after training on it from scratch:\n",
      "accuracy task 0 = 0.836\n",
      "accuracy task 1 = 0.812\n",
      "accuracy task 2 = 0.835\n"
     ]
    }
   ],
   "source": [
    "n_tasks = 3\n",
    "model_eval = ModelEval(continual_learning=False, verbose=False)\n",
    "\n",
    "print(\"Accuracy for target task after training on it from scratch:\")\n",
    "for i in range(n_tasks):\n",
    "    model_eval.model = None # reset the model\n",
    "    model_eval.train(i, epochs=100)\n",
    "    model_eval.test(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing node features\n",
      "epoch=0, train_loss=1.099, train_acc=0.136, val_acc=0.755\n",
      "epoch=10, train_loss=1.012, train_acc=0.690, val_acc=0.755\n",
      "epoch=20, train_loss=0.831, train_acc=0.716, val_acc=0.755\n",
      "epoch=30, train_loss=0.717, train_acc=0.726, val_acc=0.755\n",
      "epoch=40, train_loss=0.692, train_acc=0.731, val_acc=0.755\n",
      "epoch=50, train_loss=0.662, train_acc=0.734, val_acc=0.755\n",
      "epoch=0, train_loss=0.941, train_acc=0.618, val_acc=0.626, task[0]_val_acc=0.755\n",
      "epoch=10, train_loss=0.865, train_acc=0.618, val_acc=0.626, task[0]_val_acc=0.755\n",
      "epoch=20, train_loss=0.795, train_acc=0.618, val_acc=0.626, task[0]_val_acc=0.755\n",
      "epoch=30, train_loss=0.692, train_acc=0.618, val_acc=0.626, task[0]_val_acc=0.755\n",
      "epoch=40, train_loss=0.604, train_acc=0.632, val_acc=0.708, task[0]_val_acc=0.683\n",
      "epoch=50, train_loss=0.540, train_acc=0.654, val_acc=0.708, task[0]_val_acc=0.600\n",
      "epoch=0, train_loss=1.297, train_acc=0.524, val_acc=0.565, task[0]_val_acc=0.582, task[1]_val_acc=0.711\n",
      "epoch=10, train_loss=0.951, train_acc=0.511, val_acc=0.571, task[0]_val_acc=0.388, task[1]_val_acc=0.495\n",
      "epoch=20, train_loss=0.809, train_acc=0.536, val_acc=0.608, task[0]_val_acc=0.597, task[1]_val_acc=0.690\n",
      "epoch=30, train_loss=0.727, train_acc=0.562, val_acc=0.674, task[0]_val_acc=0.504, task[1]_val_acc=0.636\n",
      "epoch=40, train_loss=0.645, train_acc=0.592, val_acc=0.738, task[0]_val_acc=0.474, task[1]_val_acc=0.576\n",
      "epoch=50, train_loss=0.552, train_acc=0.632, val_acc=0.789, task[0]_val_acc=0.388, task[1]_val_acc=0.481\n",
      "Accuracy after training on all 3 tasks:\n",
      "accuracy task 0 = 0.387\n",
      "accuracy task 1 = 0.524\n",
      "accuracy task 2 = 0.767\n",
      "mean_accuracy = 0.621\n"
     ]
    }
   ],
   "source": [
    "model_eval = ModelEval(continual_learning=False, verbose=True, print_freq=10, print_previous_val=True)\n",
    "\n",
    "training_data = dict()\n",
    "\n",
    "for i in range(n_tasks):\n",
    "    training_data[i] = model_eval.train(i, epochs=50)\n",
    "\n",
    "print(\"Accuracy after training on all 3 tasks:\")\n",
    "model_eval.test(0)\n",
    "model_eval.test(1)\n",
    "model_eval.test(2)\n",
    "\n",
    "model_eval.print_mean_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.13326654, 0.68983424, 0.71633744, 0.7257418, 0.7305587, 0.7334866],\n",
       " [0.6182365, 0.6182365, 0.6182365, 0.6182365, 0.62004495, 0.64499587])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# train_loss_list, train_acc_list, val_loss_list, val_acc_list\n",
    "\n",
    "epochs = list(range(0, 51, 10))\n",
    "\n",
    "training_data[0][1], training_data[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing node features\n",
      "Training on task 0\n",
      "epoch=0, train_loss=1.099, train_acc=0.436, val_acc=0.755\n",
      "epoch=10, train_loss=1.012, train_acc=0.717, val_acc=0.755\n",
      "epoch=20, train_loss=0.828, train_acc=0.731, val_acc=0.755\n",
      "epoch=30, train_loss=0.715, train_acc=0.736, val_acc=0.755\n",
      "epoch=40, train_loss=0.686, train_acc=0.738, val_acc=0.755\n",
      "epoch=50, train_loss=0.659, train_acc=0.739, val_acc=0.755\n",
      "\n",
      "Training on task 1\n",
      "epoch=0, train_loss=0.939, train_acc=0.618, val_acc=0.626, task[0]_val_acc=0.755\n",
      "epoch=10, train_loss=0.864, train_acc=0.618, val_acc=0.626, task[0]_val_acc=0.755\n",
      "epoch=20, train_loss=0.807, train_acc=0.618, val_acc=0.626, task[0]_val_acc=0.755\n",
      "epoch=30, train_loss=0.717, train_acc=0.618, val_acc=0.626, task[0]_val_acc=0.755\n",
      "epoch=40, train_loss=0.628, train_acc=0.626, val_acc=0.711, task[0]_val_acc=0.707\n",
      "epoch=50, train_loss=0.559, train_acc=0.649, val_acc=0.713, task[0]_val_acc=0.641\n",
      "\n",
      "Training on task 2\n",
      "epoch=0, train_loss=1.249, train_acc=0.515, val_acc=0.558, task[0]_val_acc=0.611, task[1]_val_acc=0.704\n",
      "epoch=10, train_loss=0.955, train_acc=0.508, val_acc=0.538, task[0]_val_acc=0.391, task[1]_val_acc=0.474\n",
      "epoch=20, train_loss=0.816, train_acc=0.529, val_acc=0.591, task[0]_val_acc=0.602, task[1]_val_acc=0.704\n",
      "epoch=30, train_loss=0.738, train_acc=0.546, val_acc=0.612, task[0]_val_acc=0.541, task[1]_val_acc=0.695\n",
      "epoch=40, train_loss=0.671, train_acc=0.560, val_acc=0.635, task[0]_val_acc=0.562, task[1]_val_acc=0.678\n",
      "epoch=50, train_loss=0.602, train_acc=0.578, val_acc=0.740, task[0]_val_acc=0.448, task[1]_val_acc=0.562\n",
      "\n",
      "Testing on task 0\n",
      "accuracy task 0 = 0.452\n",
      "\n",
      "Testing on task 1\n",
      "accuracy task 1 = 0.608\n",
      "\n",
      "Testing on task 2\n",
      "accuracy task 2 = 0.677\n",
      "\n",
      "mean_accuracy = 0.634\n",
      "backward_transfer = -0.503\n"
     ]
    }
   ],
   "source": [
    "model_eval = ModelEval(continual_learning=True, lambda_=0.1,\n",
    "                       verbose=True, print_freq=10, print_previous_val=True)\n",
    "\n",
    "num_tasks = 3\n",
    "\n",
    "for i in range(num_tasks):\n",
    "    print(f\"Training on task {i}\")\n",
    "    model_eval.train(i, epochs=50)\n",
    "    print()\n",
    "\n",
    "for i in range(num_tasks):\n",
    "    print(f\"Testing on task {i}\")\n",
    "    model_eval.test(i)\n",
    "    print()\n",
    "\n",
    "model_eval.print_mean_accuracy()\n",
    "model_eval.print_backward_transfer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4a0cdf5044e235b24d1fc042fb09c724f9ff16da5a82a5cb2270a9975034c9c0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
